{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label DP SGD\n",
    "\n",
    "This notebook walks through how to train a model to recognize hand written\n",
    "digits using label differentially private gradient decent and the MNIST dataset.\n",
    "In this setting, one party has the images and the other party has the labels.\n",
    "They would like to collaborate to train a model without revealing their data.\n",
    "\n",
    "Before starting, install the tf-shell package.\n",
    "\n",
    "```bash\n",
    "pip install tf-shell\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import some modules and set up tf-shell. The parameters are for the SHELL\n",
    "encryption library, which tf-shell uses, and mostly depend on the multiplicative\n",
    "depth of the computation to be performed. This example performs back\n",
    "propagation, thus the multiplicative depth is determined by the number of\n",
    "layers. For more information, see [SHELL](https://github.com/google/shell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 06:18:05.175618: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-29 06:18:05.198038: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import tf_shell\n",
    "import tf_shell_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default batch size (must be less that the chosen ciphertext ring degree\n",
    "# so anything less than 2**10 is fine). This will be used for validation, but\n",
    "# for training using autocontext (as below) the batch size is determined by the\n",
    "# ciphertext parameters.\n",
    "batch_size = 2**10\n",
    "\n",
    "# Setup the dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = np.reshape(x_train, (-1, 784)), np.reshape(x_test, (-1, 784))\n",
    "x_train, x_test = x_train / np.float32(255.0), x_test / np.float32(255.0)\n",
    "y_train, y_test = tf.one_hot(y_train, 10), tf.one_hot(y_test, 10)\n",
    "\n",
    "epochs = 1\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=2048)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .repeat(count=epochs)\n",
    ")\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters:\n",
      "log_n: 12\n",
      "t: 65537\n",
      "qs: 288230376151760897 288230376152137729 \n"
     ]
    }
   ],
   "source": [
    "# Turn on the shell optimizer to use autocontext.\n",
    "tf_shell.enable_optimization()\n",
    "use_fast_reduce_sum = True\n",
    "\n",
    "m = tf_shell_ml.TfShellSequential(\n",
    "    [\n",
    "        tf_shell_ml.ShellDense(\n",
    "            64,\n",
    "            activation=tf_shell_ml.relu,\n",
    "            activation_deriv=tf_shell_ml.relu_deriv,\n",
    "            use_fast_reduce_sum=use_fast_reduce_sum,\n",
    "        ),\n",
    "        tf_shell_ml.ShellDense(\n",
    "            10,\n",
    "            activation=tf.nn.softmax,\n",
    "            use_fast_reduce_sum=use_fast_reduce_sum,\n",
    "        ),\n",
    "    ],\n",
    "    lambda: tf_shell.create_autocontext64(\n",
    "        log2_cleartext_sz=12,\n",
    "        scaling_factor=3,\n",
    "        noise_offset_log2=68,\n",
    "    ),\n",
    "    True,\n",
    ")\n",
    "\n",
    "m.compile(\n",
    "    shell_loss=tf_shell_ml.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "train_datset = m.set_dataset_batching(train_dataset)\n",
    "\n",
    "# m.build([batch_size, 784])  # do not build if using autoparams\n",
    "# m(train_dataset)\n",
    "# m.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 06:18:37.535177: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-09-29 06:18:37.535200: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-09-29 06:18:37.535262: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters:\n",
      "log_n: 12\n",
      "t: 65537\n",
      "qs: 288230376151760897 288230376152137729 \n",
      "58/58 [==============================] - 1160s 20s/step - num_slots: 4096.0000 - val_categorical_accuracy: 0.1018\n"
     ]
    }
   ],
   "source": [
    "# Set up tensorboard logging.\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "fast_str = \"-fast\" if use_fast_reduce_sum else \"\"\n",
    "logdir = os.path.abspath(\"\") + f\"/tflogs/dp-sgd{fast_str}-{stamp}\"\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logdir,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "history = m.fit(train_dataset, epochs=1, validation_data=val_dataset, callbacks = [tboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_shell_sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shell_dense (ShellDense)    multiple                  50176     \n",
      "                                                                 \n",
      " shell_dense_1 (ShellDense)  multiple                  640       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50816 (198.50 KB)\n",
      "Trainable params: 50816 (198.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
