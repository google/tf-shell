{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing HE with tf-shell\n",
    "\n",
    "There are two forms of parallelism in `tf-shell`.\n",
    "\n",
    "First, many of tf-shell's operations internally parallelize over the dimension\n",
    "of the input. For example, multiplying two [slot, 3] ciphertexts (i.e. a vector\n",
    "of ciphertexts with length 3) may run the three element-wise multiplications in\n",
    "parallel. This is performed using TensorFlow's thread pool.\n",
    "\n",
    "Second is graph level parallelism. This is where multiple operations are run in\n",
    "parallel. As an extension of TensorFlow, `tf-shell` supports this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 19:47:41.337185: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-29 19:47:41.532076: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Generating key\n",
      "INFO: Generating rotation key\n",
      "INFO: Generating rotation key\n"
     ]
    }
   ],
   "source": [
    "import tf_shell\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "context = tf_shell.create_context64(\n",
    "    log_n=10,\n",
    "    main_moduli=[8556589057, 8388812801],\n",
    "    plaintext_modulus=40961,\n",
    "    scaling_factor=3,\n",
    "    seed=\"test_seed\",\n",
    ")\n",
    "\n",
    "secret_key = tf_shell.create_key64(context)\n",
    "rotation_key = tf_shell.create_rotation_key64(context, secret_key)\n",
    "\n",
    "single_pt = tf.random.uniform([context.num_slots, 1], dtype=tf.float32, maxval=10)\n",
    "single_ct = tf_shell.to_encrypted(single_pt, secret_key, context)\n",
    "\n",
    "vector_pt = tf.random.uniform([context.num_slots, 8], dtype=tf.float32, maxval=10)\n",
    "vector_ct = tf_shell.to_encrypted(vector_pt, secret_key, context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Op Level Parallelism\n",
    "\n",
    "Benchmark the time taken to multiply two ciphertexts. The first test performs\n",
    "multiplication between two individual ciphertexts (each has shape [slots, 1]).\n",
    "The second test measures element-wise multiplication between [slot, 8]\n",
    "ciphertexts, i.e. a vector of ciphertexts of length 8.\n",
    "\n",
    "Without parallelism, the element-wise multiplication is expected to take 8 times\n",
    "longer than the individual multiplication, but we show here this is not the\n",
    "case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply single ct * single ct: 0.028574070000104257\n",
      "Multiply vector ct * vector ct: 0.038458762001027935\n"
     ]
    }
   ],
   "source": [
    "def mul_single_ct_ct():\n",
    "    return single_ct * single_ct\n",
    "\n",
    "def mul_vector_ct_ct():\n",
    "    return vector_ct * vector_ct\n",
    "\n",
    "single_ct_ct_time = min(timeit.Timer(mul_single_ct_ct).repeat(repeat=10, number=100))\n",
    "print(f\"Multiply single ct * single ct: {single_ct_ct_time}\")\n",
    "\n",
    "vector_ct_ct_time = min(timeit.Timer(mul_vector_ct_ct).repeat(repeat=10, number=100))\n",
    "print(f\"Multiply vector ct * vector ct: {vector_ct_ct_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Level Parallelism\n",
    "\n",
    "Benchmark the time taken to perform two multiplications. The first test is run\n",
    "in TensorFlow's eager mode, meaning the two multiplications are run\n",
    "sequentially. The second test is run in graph mode, and tensorflow may run the\n",
    "two multiplications in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imperitive execution: 21.420444982000845\n",
      "Graph-based execution: 9.077498362999904\n"
     ]
    }
   ],
   "source": [
    "large_pt = tf.random.uniform([context.num_slots, 10000], dtype=tf.float32, maxval=10)\n",
    "large_ct = tf_shell.to_encrypted(large_pt, secret_key, context)\n",
    "\n",
    "def fn():\n",
    "    # The two operations may be run in parallel when in graph mode.\n",
    "    return [large_ct + 1, large_ct + 2]\n",
    "\n",
    "def eager():\n",
    "    return fn()\n",
    "\n",
    "@tf.function\n",
    "def deferred():\n",
    "    return fn()\n",
    "\n",
    "single_ct_ct_time = min(timeit.Timer(eager).repeat(repeat=1, number=100))\n",
    "print(f\"Imperitive execution: {single_ct_ct_time}\")\n",
    "\n",
    "vector_ct_ct_time = min(timeit.Timer(deferred).repeat(repeat=1, number=100))\n",
    "print(f\"Graph-based execution: {vector_ct_ct_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
