{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on IMDB dataset\n",
    "\n",
    "This notebook walks through how perform sentament analysis on the IMDB dataset.\n",
    "In this setting, one party has the reviews and the other party has the labels.\n",
    "The party with the labels is helping the party with the reviews train a model\n",
    "without sharing the labels themselves.\n",
    "\n",
    "Before starting, install tf-shell and the dataset.\n",
    "\n",
    "```bash\n",
    "pip install tf-shell\n",
    "pip install tensorflow_hub tensorflow_datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:49:11.867640: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-10 23:49:11.867982: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-10 23:49:11.869644: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-10 23:49:11.895495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 23:49:12.500017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/workspaces/tf-shell/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import tf_shell\n",
    "import tf_shell_ml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters for the SHELL encryption library.\n",
    "context = tf_shell.create_context64(\n",
    "    log_n=12,\n",
    "    main_moduli=[288230376151760897, 288230376152137729],\n",
    "    plaintext_modulus=4294991873,\n",
    "    scaling_factor=3,\n",
    "    mul_depth_supported=3,\n",
    "    seed=\"test_seed\",\n",
    ")\n",
    "\n",
    "# Create the secret key for encryption and a rotation key (rotation key is\n",
    "# an auxilary key required for operations like roll or matmul).\n",
    "secret_key = tf_shell.create_key64(context)\n",
    "public_rotation_key = tf_shell.create_rotation_key64(context, secret_key)\n",
    "\n",
    "# The batch size is determined by the ciphertext parameters, specifically the\n",
    "# schemes polynomial's ring degree because tf-shell uses batch axis packing.\n",
    "# Furthermore, two micro-batches to run in parallel.\n",
    "batch_size = context.num_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:49:58.773005: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /home/vscode/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Size...: 100%|██████████| 80/80 [00:13<00:00,  5.97 MiB/s]rl]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:13<00:00, 13.39s/ url]\n",
      "2024-06-10 23:51:28.949194: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-06-10 23:51:28.949578: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/vscode/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n",
      "Label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:51:30.315651: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most used words: ['', '[UNK]', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'it']\n",
      "Dictionary size: 50000\n"
     ]
    }
   ],
   "source": [
    "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_data, val_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n",
    "\n",
    "# Print the first example.\n",
    "for review, label in train_data.take(1):\n",
    "    print(\"Review:\", review.numpy().decode('utf-8'))\n",
    "    print(\"Label:\", label.numpy())\n",
    "\n",
    "epochs = 3\n",
    "train_data = train_data.shuffle(buffer_size=2048).batch(batch_size, drop_remainder=True).repeat(count=epochs)\n",
    "val_data = val_data.shuffle(buffer_size=2048).batch(batch_size, drop_remainder=True)\n",
    "test_data = test_data.shuffle(buffer_size=2048).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "vocab_size = 50000  # This dataset has 92061 unique words.\n",
    "max_length = 200\n",
    "embedding_dim = 50\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=max_length)\n",
    "    # TODO use pad_to_max_tokens instead of output_sequence_length?\n",
    "\n",
    "vectorize_layer.adapt(train_data.map(lambda text, label: text))\n",
    "\n",
    "print(\"Most used words:\", vectorize_layer.get_vocabulary()[:10])\n",
    "print(\"Dictionary size:\", len(vectorize_layer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trainable layers.\n",
    "embedding_layer = tf_shell_ml.ShellEmbedding(\n",
    "    vocab_size + 1,  # +1 for OOV token.\n",
    "    embedding_dim,\n",
    ")\n",
    "# TODO dropout layer?\n",
    "hidden_layer = tf_shell_ml.ShellDense(\n",
    "    16,\n",
    "    activation=tf_shell_ml.relu,\n",
    "    activation_deriv=tf_shell_ml.relu_deriv,\n",
    ")\n",
    "# TODO dropout layer?\n",
    "output_layer = tf_shell_ml.ShellDense(1,\n",
    "    activation=tf.nn.softmax,\n",
    ")\n",
    "\n",
    "## Call the layers once to create the weights.\n",
    "#y1 = hidden_layer(tf.zeros((batch_size, 784)))\n",
    "#y2 = output_layer(y1)\n",
    "\n",
    "loss_fn = tf_shell_ml.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "emb_optimizer = tf.keras.optimizers.Adam(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the `train_step` function which will be called for each batch on an\n",
    "encrypted batch of labels, y. The function first does a forward on the plaintext\n",
    "image x to compute a predicted label, then does backpropagation using the\n",
    "encrypted label y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, enc_y):\n",
    "    # Forward pass always in plaintext\n",
    "    # y //= max_length  # Normalize for reduce_sum.\n",
    "    y = embedding_layer(x)\n",
    "    y = tf_shell.reshape(y, (batch_size, max_length * embedding_dim))\n",
    "    # Could also do reduce_sum and division to replicate GlobalAveragePooling1D layer.\n",
    "    # y = tf_shell.reduce_sum(y, axis=1)\n",
    "\n",
    "    y = hidden_layer(y)\n",
    "    y_pred = output_layer(y)\n",
    "\n",
    "    # Backward pass.\n",
    "    dJ_dy_pred = loss_fn.grad(enc_y, y_pred)\n",
    "    dJ_dw2, dJ_dx2 = output_layer.backward(dJ_dy_pred, public_rotation_key)\n",
    "    dJ_dw1, dJ_dx1 = hidden_layer.backward(dJ_dx2, public_rotation_key)\n",
    "\n",
    "    dJ_dx1_reshaped = tf_shell.reshape(dJ_dx1, (batch_size, max_length, embedding_dim))\n",
    "    # Could also tile up to this shape to replicate GlobalAveragePooling1D layer.\n",
    "    # dJ_dx1_reshaped = tf_shell.broadcast_to(\n",
    "    #     dJ_dx1, (batch_size, max_length, embedding_dim)\n",
    "    # )\n",
    "\n",
    "    embedding_layer.backward_accum(dJ_dx1_reshaped, public_rotation_key)\n",
    "\n",
    "    # dJ_dw0, _ = embedding_layer.backward(dJ_dx1_reshaped, public_rotation_key)\n",
    "\n",
    "    # dJ_dw0, the embedding layer gradient, would usually have outer shape [1]\n",
    "    # for the 1 output classes. tf-shell instead back propagates in two\n",
    "    # mini-batches per batch resulting in two gradients of shape [2].\n",
    "    # Furthermore, the gradients are in an \"expanded\" form where the gradient is\n",
    "    # repeated by the size of the batch. Said another way, if\n",
    "    # real_grad_top/bottom is the \"real\" gradient of shape [10] from the\n",
    "    # top/bottom halves of the batch:\n",
    "    #\n",
    "    # dJ_dw = tf.concat([\n",
    "    #   tf.repeat(\n",
    "    #       tf.expand_dims(real_grad_top, 0), repeats=[batch_sz // 2], axis=0\n",
    "    #   ),\n",
    "    #   tf.repeat(\n",
    "    #       tf.expand_dims(real_grad_bottom, 0), repeats=[batch_sz // 2], axis=0\n",
    "    #   )\n",
    "    # ])\n",
    "    #\n",
    "    # This repetition is result of the SHELL library using a packed\n",
    "    # representation of ciphertexts for efficiency. As such, if the ciphertexts\n",
    "    # need to be sent over the network, they may be masked and packed together\n",
    "    # before being transmitted to the party with the key.\n",
    "    #\n",
    "    # Only return the weight gradients at [0], not the bias gradients at [1].\n",
    "    # The bias is not used in this test.\n",
    "    # return [dJ_dw2[0], dJ_dw1[0], dJ_dw0[0]]\n",
    "    return [dJ_dw2[0], dJ_dw1[0]]\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step_wrapper(x_batch, y_batch):\n",
    "    # Encrypt the batch of secret labels y.\n",
    "    enc_y_batch = tf_shell.to_encrypted(y_batch, secret_key, context)\n",
    "\n",
    "    # Run the training step. The top and bottom halves of the batch are\n",
    "    # treated as two separate mini-batches run in parallel to maximize\n",
    "    # efficiency.\n",
    "    enc_grads = train_step(x_batch, enc_y_batch)\n",
    "\n",
    "    # Decrypt the weight gradients. In practice, the gradients should be\n",
    "    # noised before decrypting.\n",
    "    repeated_grads = [tf_shell.to_tensorflow(g, secret_key) for g in enc_grads]\n",
    "\n",
    "    # Pull out grads from the top and bottom batches.\n",
    "    top_grad = [g[0] for g in repeated_grads]\n",
    "    bottom_grad = [g[batch_size // 2] for g in repeated_grads]\n",
    "\n",
    "    # Apply the gradients to the model.\n",
    "    weights = output_layer.weights + hidden_layer.weights\n",
    "    optimizer.apply_gradients(zip(top_grad, weights))\n",
    "    optimizer.apply_gradients(zip(bottom_grad, weights))\n",
    "\n",
    "    # Apply the embedding layer gradient (contains both batches).\n",
    "    # optimizer.apply_gradients(embedding_layer.decrypt_grad(secret_key), embedding_layer.weights)\n",
    "    emb_optimizer.apply_gradients(zip([embedding_layer.decrypt_grad(secret_key)], embedding_layer.weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the training loop. Each inner iteration runs two batches of size\n",
    "$2^{12-1}$ simultaneously.\n",
    "\n",
    "Tensorboard can be used to visualize the training progress. See cell output for\n",
    "command to start tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To start tensorboard, run: tensorboard --logdir /tmp/tflogs --host 0.0.0.0\n",
      "\ttensorboard profiling requires: pip install tensorboard_plugin_profile\n",
      "\ttrain loss: nan\taccuracy: 0.5001627802848816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:51:31.724473: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvalidation loss: nan\taccuracy: 0.4974365234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 23:51:32.024516: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-06-10 23:51:32.059464: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-06-10 23:51:32.059493: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 / 9, Time Stamp: 1.4508495330810547\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "\n",
    "def check_accuracy(dataset):\n",
    "    average_loss = 0\n",
    "    average_accuracy = 0\n",
    "    for x, y in dataset:\n",
    "        y = tf.cast(y, tf.float32)\n",
    "        y = tf.reshape(y, (batch_size, 1))\n",
    "\n",
    "        y_pred = vectorize_layer(x)\n",
    "        # y_pred //= max_length  # Normalize for reduce_sum.\n",
    "        y_pred = embedding_layer(y_pred)\n",
    "        y_pred = tf_shell.reshape(y_pred, (batch_size, max_length * embedding_dim))\n",
    "        # y_pred = tf_shell.reduce_sum(y_pred, axis=1)\n",
    "        y_pred = hidden_layer(y_pred)\n",
    "        y_pred = output_layer(y_pred)\n",
    "        \n",
    "        loss = tf.reduce_mean(loss_fn(y, y_pred))\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(y, tf.round(y_pred)), tf.float32))\n",
    "        average_loss += loss\n",
    "        average_accuracy += accuracy\n",
    "    average_loss /= len(dataset)\n",
    "    average_accuracy /= len(dataset)\n",
    "\n",
    "    return average_loss, average_accuracy\n",
    "\n",
    "\n",
    "# Set up tensorboard logging.\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = os.path.abspath(\"\") + \"/tflogs/sentiment-%s\" % stamp\n",
    "print(f\"To start tensorboard, run: tensorboard --logdir /tmp/tflogs --host 0.0.0.0\")\n",
    "print(f\"\\ttensorboard profiling requires: pip install tensorboard_plugin_profile\")\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Initial accuracy\n",
    "loss, accuracy = check_accuracy(train_data)\n",
    "tf.print(f\"\\ttrain loss: {loss}\\taccuracy: {accuracy}\")\n",
    "loss, accuracy = check_accuracy(val_data)\n",
    "tf.print(f\"\\tvalidation loss: {loss}\\taccuracy: {accuracy}\")\n",
    "\n",
    "# Iterate over the batches of the dataset.\n",
    "for step, (x_batch, y_batch) in enumerate(train_data.take(batch_size)):\n",
    "    print(\n",
    "        f\"Step: {step} / {len(train_data)}, Time Stamp: {time.time() - start_time}\"\n",
    "    )\n",
    "\n",
    "    y_batch = tf.cast(y_batch, tf.float32)\n",
    "    y_batch = tf.reshape(y_batch, (batch_size, 1))\n",
    "\n",
    "    if step == 0:\n",
    "        tf.summary.trace_on(graph=True, profiler=True, profiler_outdir=logdir)\n",
    "\n",
    "    x_batch = vectorize_layer(x_batch)  # No shape inference, do outside tf.function\n",
    "    train_step_wrapper(x_batch, y_batch)\n",
    "\n",
    "    if step == 0:\n",
    "        with writer.as_default():\n",
    "            tf.summary.trace_export(name=\"sentiment\", step=step)\n",
    "\n",
    "    loss, accuracy = check_accuracy(train_data)\n",
    "    tf.print(f\"\\ttrain loss: {loss}\\taccuracy: {accuracy}\")\n",
    "    loss, accuracy = check_accuracy(val_data)\n",
    "    tf.print(f\"\\tvalidation loss: {loss}\\taccuracy: {accuracy}\")\n",
    "\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar(\"loss\", loss, step=step)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy, step=step)\n",
    "\n",
    "\n",
    "print(f\"Total training time: {time.time() - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
