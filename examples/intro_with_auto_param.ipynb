{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to tf-shell with AutoParameter Optimization\n",
    "\n",
    "To get started, `pip install tf-shell`.\n",
    "\n",
    "`tf-shell` is tightly integrated with TensorFlow's graph execution engine and\n",
    "extends TensorFlow's graph compiler with some convenient\n",
    "homomorphic-encryption (HE) specific features.\n",
    "\n",
    "In this notebook, we will demonstrate how to use `tf-shell` to automatically\n",
    "choose low level parameters (like the plaintext modulus and ciphertext moduli)\n",
    "for the BGV HE scheme.\n",
    "These moduli depend on the depth of a computation, and must be fixed before\n",
    "the computation starts.\n",
    "In other examples, these moduli are chosen manually however it is convenient to\n",
    "let `tf-shell` automatically choose these parameters for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 15:46:58.912539: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-12 15:46:58.935203: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf_shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the function we'd like to compute.\n",
    "TensorFlow will first trace this function (without executing it) to build a\n",
    "graph of the computation.\n",
    "Then, during a graph compiler optimization pass, `tf-shell` will replace the\n",
    "\"autoparameters\" placeholder with moduli generated for this specific computation\n",
    "based on statistical estimation of the noise growth, the initial plaintext size,\n",
    "and the scaling factor.\n",
    "\n",
    "Note, the `create_autocontext64` function must be called from inside a\n",
    "`tf.function` in order to execute in non-eager (deferred) mode.\n",
    "This ensures TensorFlow creates the computation graph which is required to\n",
    "choose the moduli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def foo(cleartext_a, cleartext_b):\n",
    "    shell_context = tf_shell.create_autocontext64(\n",
    "        log2_cleartext_sz=4,  # Maximum size of the cleartexts (ignoring the scaling factor).\n",
    "        scaling_factor=1,  # The scaling factor (analagous to fixed-point but not base 2).\n",
    "        noise_offset_log2=32,  # Extra buffer for noise growth.\n",
    "    )\n",
    "    key = tf_shell.create_key64(shell_context)\n",
    "    a = tf_shell.to_encrypted(cleartext_a, key, shell_context)\n",
    "    b = tf_shell.to_shell_plaintext(cleartext_b, shell_context)\n",
    "\n",
    "    intermediate = a * b\n",
    "    result = tf_shell.to_tensorflow(intermediate, key)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters:\n",
      "log_n: 11\n",
      "t: 12289\n",
      "qs: 288230376151748609 12289 \n",
      "tf.Tensor([ 4 10 18 ...  0  0  0], shape=(2048,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf_shell.enable_optimization()\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "c = foo(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall `tf-shell` treats the first dimension of data as the packing dimension\n",
    "of the BGV scheme.\n",
    "In the example above, the three elements of the input vectors are packed into\n",
    "this first dimension for efficiency purposes.\n",
    "\n",
    "Note however, that the remaining slots in the ciphertexts went unused and the\n",
    "number of slots was chosen automatically during graph optimization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
